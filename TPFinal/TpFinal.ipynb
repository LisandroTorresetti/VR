{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo práctico Integrador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumno:** Torresetti Lisandro\n",
    "\n",
    "**Padrón:** 99846\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Realizar un programa que permita determiar la pose de las piezas dispuestas en la zona de trabajo de manera que el robot pueda tomarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import PIL.ExifTags\n",
    "import PIL.Image\n",
    "import pprint\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths\n",
    "\n",
    "BLOCKS_PATH = './imagenes/img_bloques'\n",
    "BLOCKS_CHALLENGE_PATH = './imagenes/img_bloques_desafio'\n",
    "CALIBRATION_SET_1 = './imagenes/img_cal_set1'\n",
    "CALIBRATION_SET_2 = './imagenes/img_cal_set2'\n",
    "\n",
    "# Constants\n",
    "\n",
    "EXTRA_IMG = 'imgCalExtr'\n",
    "IMG_NAME = 'imgBloque'\n",
    "CALIBRATION_IMG_NAME = 'img_cal1'\n",
    "\n",
    "# Debug\n",
    "IMGS_DEBUG = ['imgBloque1', 'imgBloque2', 'imgBloque3', 'imgBloque4', 'imgBloque16']\n",
    "CHALLENGE_IMGS = IMGS_DEBUG[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to make the plots\n",
    "def plotter(image, title = '', imgSize = (16,9), grayScale = False):\n",
    "    plt.figure(figsize=imgSize)\n",
    "    plt.title(title, fontsize = 16, fontweight = \"bold\")\n",
    "    plt.imshow(image) if not grayScale else plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "# Auxiliary function to load all the images from path\n",
    "def loadImages(path):\n",
    "    imgNames = glob(path + '/*')\n",
    "    result = {}\n",
    "    for imgName in imgNames:\n",
    "        img = cv.imread(imgName)\n",
    "        result[re.sub(r'^.*/([^.]*).*$', r'\\1', imgName)] = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    return result\n",
    "\n",
    "# Creates a mask from the image and the specified position. Remember: in OpenCv the coorinates are (Y, X)\n",
    "def createMask(img, position, lowerMultiplier = 6, upperMultiplier = 6):\n",
    "    initialPoint, endPoint = position\n",
    "    colorMean, colorStd = cv.meanStdDev(img[initialPoint[1]:endPoint[1], initialPoint[0]:endPoint[0], :])\n",
    "    return cv.inRange(img, colorMean - colorStd * lowerMultiplier,  colorMean + colorStd * upperMultiplier)\n",
    "\n",
    "# Applies a mask to the img. Returns a new image with the mask applied\n",
    "def applyMask(img, mask):\n",
    "    return cv.bit\n",
    "\n",
    "# Plot the histogram for the first 'amountOfBlocks' blocks\n",
    "def plotHistograms(imgs, bins = 50, amountOfBlocks = 5):\n",
    "    fig, axs = plt.subplots(amountOfBlocks)\n",
    "    fig.suptitle('Histograms', fontsize=18, fontweight='bold')\n",
    "    imgsNames = [IMG_NAME + str(i) for i in range(1, amountOfBlocks + 1)]\n",
    "    xTicks = np.arange(0, 260, 10)\n",
    "    yTicks = np.arange(0, 300000, 30000)\n",
    "    for imgNum, imgName in enumerate(imgsNames):\n",
    "        axs[imgNum].set_title(imgName, fontsize = 16, fontweight='bold')\n",
    "        axs[imgNum].grid()\n",
    "        axs[imgNum].hist(imgs[imgName].ravel(),bins,[0,256], color='orange')\n",
    "        axs[imgNum].set_xticks(xTicks)\n",
    "        axs[imgNum].set_yticks(yTicks)\n",
    "    \n",
    "    fig.set_size_inches(16, 10)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "# Performs the Otsu binarization mehtod. Returns a dictionary with the images binarized\n",
    "def otsuBinarization(imgs, thresh = 100):\n",
    "    result = {}\n",
    "    for imgName, img in imgs.items():\n",
    "        ret, imgBin = cv.threshold(img, thresh, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        result[imgName] = imgBin\n",
    "    return result\n",
    "\n",
    "# Prints the contour info for an image\n",
    "def printBlocksInfo(contoursInfo):\n",
    "    print('RESULTS')\n",
    "    for blockName, info in contoursInfo.items():\n",
    "        if isSpecialImage(blockName):\n",
    "            for block_i_info in info:\n",
    "                printInfoWithFormat(blockName, block_i_info)\n",
    "            continue\n",
    "            \n",
    "        printInfoWithFormat(blockName, info)\n",
    "\n",
    "# Prints the info of a block with a format\n",
    "def printInfoWithFormat(blockName, info):\n",
    "    print(f'''\n",
    "                Block Num: {blockName}\n",
    "\n",
    "                    Area: {info[AREA]}\n",
    "                    Perimeter: {info[PERIMETER]}\n",
    "                    Width: {np.round(info[SIDES][0], 4)}\n",
    "                    Height: {np.round(info[SIDES][1], 4)}\n",
    "                    Centroid: {info[CENTER]}\n",
    "                    Aspect Relation: {info[ASPECT_RELATION]}\n",
    "                    Orientation: {info[ORIENTATION][2]}\n",
    "                '''\n",
    "    )\n",
    "\n",
    "# Returns if the image is the one who contains more than one block\n",
    "def isSpecialImage(imgName):\n",
    "    return imgName == IMG_NAME + '16'\n",
    "\n",
    "# Draws the bounding box and the center of the block using minAreaRect. Returns an image with the draws\n",
    "def drawContours(img, blockInfo):\n",
    "    outputImg = img.copy()\n",
    "    contour = blockInfo[CONTOUR]\n",
    "    rect = cv.minAreaRect(contour)\n",
    "    box = cv.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    cv.drawContours(outputImg, [box], 0, (255, 0, 0), 2)\n",
    "    cv.circle(outputImg, blockInfo[CENTER], radius=5, color=(0, 0, 0), thickness=-3)\n",
    "    return outputImg\n",
    "\n",
    "# For debugging\n",
    "def debug(imgs, grayScale=False, debugImgs=IMGS_DEBUG):\n",
    "    for imgName in debugImgs:\n",
    "        plotter(imgs[imgName], imgName, grayScale=grayScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Se cargan las imágenes de los bloques y las de los sets de calibración. Una vez que se carguen todas se procede a preprocesarlas para corregirlas y eliminar el ruido que posean y que pueda interferir en el análisis de las futuras secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originalBlocks = loadImages(BLOCKS_PATH)\n",
    "calibrationSet1 = loadImages(CALIBRATION_SET_1)\n",
    "calibrationSet2 = loadImages(CALIBRATION_SET_2)\n",
    "\n",
    "# There is an image for the extrinsic calibration, I will store it in some variable and \n",
    "# then it will be delete of the set of block images\n",
    "extrinsicCalibration = originalBlocks[EXTRA_IMG]\n",
    "del originalBlocks[EXTRA_IMG]\n",
    "\n",
    "# Just for check if its all right\n",
    "debug(originalBlocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea una máscara con el tablero verde para poder eliminar el ruido de los otros elementos que se encuentran en la imagen. Para crearla, se toma una porción de 'imgBloque1' y otra de 'imgBloque2' para luego hacer un OR entre ambas y obtener una máscara que sólo abarque el tablero verde. De esta forma todos los elementos que no se encuentren en el tablero serán 'eliminados'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position = ((x1, y1), (x2, y2))\n",
    "maskPosition1 = ((125, 280), (480, 450))\n",
    "blocksMask1 = createMask(originalBlocks['imgBloque1'], maskPosition1)\n",
    "\n",
    "maskPosition2 = ((125, 50), (480, 250))\n",
    "blocksMask2 = createMask(originalBlocks['imgBloque4'], maskPosition2)\n",
    "blocksMask = cv.bitwise_or(blocksMask1, blocksMask2)\n",
    "blocksMask = cv.medianBlur(blocksMask, 5)\n",
    "\n",
    "blocksWithMask = {}\n",
    "for imgName, img in originalBlocks.items():\n",
    "    img = cv.medianBlur(img, 5)\n",
    "    blocksWithMask[imgName] = cv.bitwise_and(img, img, mask=blocksMask)\n",
    "\n",
    "# DEBUG\n",
    "debug(blocksWithMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener una imagen que solo posea la figura del bloque se vuelve a crear una máscara, pero esta vez con porciones de los bloques, para hacer un promedio entre la media y el desvío estandar de cada uno de ellos, con el fin de que sea más general la máscara y no se base en los datos de un solo bloque. Se utilizarán los bloques de las imágenes 1, 2 y 3 para obtener la máscara deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocks Positions\n",
    "block1 = ((325, 110), (400, 125))\n",
    "block2 = ((285, 150), (325, 195))\n",
    "block3 = ((400, 150), (450, 200))\n",
    "blocks = [block1, block2, block3]\n",
    "\n",
    "# Draw a red line to verify the positions\n",
    "for blockNum, block in enumerate(blocks):\n",
    "    testImg = blocksWithMask[IMG_NAME + str(blockNum + 1)].copy()\n",
    "    cv.line(testImg, block[0], block[1], (255,0,0), 5)\n",
    "    plotter(testImg, IMG_NAME + str(blockNum + 1))\n",
    "\n",
    "# Get statistics about each block to compute the mask\n",
    "totalMeanBlocks = 0\n",
    "totalStdBlocks = 0\n",
    "for blockNum, blockPosition in enumerate(blocks):\n",
    "    initialPoint, endPoint = blockPosition\n",
    "    imgName = IMG_NAME + str(blockNum + 1)\n",
    "    blockImg = blocksWithMask[imgName][initialPoint[1]:endPoint[1], initialPoint[0]:endPoint[0], :]\n",
    "    meanBlock, stdBlock = cv.meanStdDev(blockImg)\n",
    "    totalMeanBlocks += meanBlock\n",
    "    totalStdBlocks += stdBlock\n",
    "    plotter(blockImg, imgName, imgSize=(8,5))\n",
    "\n",
    "meanBlocks = totalMeanBlocks / len(blocks)\n",
    "stdBlocks = totalStdBlocks / len(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {meanBlocks} \\nStd: {stdBlocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coninuación se aplican los datos obtenidos a todas las imágenes para obtnener sólo la figura de los bloques en cada una de ellas. Los resultados serán guardados en **blocksWithMask** en escala de grises, 'pisando' los valores que se obtuvieron anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgName, img in blocksWithMask.items():\n",
    "    mask_i = cv.inRange(img, meanBlocks - stdBlocks * 6,  meanBlocks + stdBlocks * 6)\n",
    "    blocksWithMask[imgName] = cv.cvtColor(cv.bitwise_and(img, img, mask=mask_i), cv.COLOR_RGB2GRAY)\n",
    "\n",
    "debug(blocksWithMask, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las imágenes poseen ciertas imperfecciones, como por ejemplo puntos negros dentro de los bloques o problemas en los bordes de los mismos. Se procede a binarizarlas para poder aplicarles operaciónes morfológicas y así corregir estas imperfecciones. Antes de realizar esto, se grafican los histogramas de dos imágenes para ver la distribución de los valores y así poder elegir un valor de _threshold_ adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(blocksWithMask, amountOfBlocks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de los histogramas es el esperado, ya que el porcentaje de color del bloque es pequeño en comparación con toda la imagen que es casi en su totalidad negra. Se utilizará un _threshold_ de 100 para realizar la binarización de las imágenes por el método de **Otsu** que se describe a continuación.\n",
    "\n",
    "**Método de Otsu:**\n",
    "Calcula el valor de umbral de forma que la dispersión dentro de cada segmento sea lo más pequeña posible, pero al mismo tiempo la dispersión sea lo más alta posible entre segmentos diferentes. Presu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binarizedBlocks = otsuBinarization(blocksWithMask)\n",
    "debug(binarizedBlocks, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar los problemas mencionados y que se encuentran a simple vista, se aplicará la operación morfológica de dilatación con un _Structural element_ de 4x1. Al resultado de esta operación se le aplicará un filtro de mediana con un kernel de 5x5. El resultado de estas operaciones se almacenará en la variable _final blocks_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will contain the final result of all the previous operation \n",
    "# plus the next one for each block image\n",
    "kernelDilate =np.ones((4,1), np.uint8)\n",
    "finalBlocks = {}\n",
    "for blockName, blockImg in binarizedBlocks.items():\n",
    "    finalBlocks[blockName] = cv.medianBlur(cv.dilate(blockImg, kernelDilate), 5)\n",
    "\n",
    "debug(finalBlocks, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto se da por finalizado el preprocesamiento de las imágenes. Los resultados obtenidos se utilizarán en las siguientes secciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Calibración Intrínseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de parámetros intrínsecos describe todos los parámetros internos de la cámara. La matriz contiene las distancias focales ($f_x$ y $f_y$) y los centros ópticos ($c_x$ y $c_y$) expresados en coordenadas de píxeles. En un modelo ideal $f_x = f_y = f$, sin embargo esto en la realidad estos valores pueden diferir debido a fallas en el sensor de la cámara digital. La matriz de parámetros intrínsecos es la siguiente:\n",
    "$$\\begin{bmatrix} fx & s & cx \\\\ 0 & fy & cy \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "Una cámara puede estar sujeta a distorsiones radiales o tangenciales, llevando a un _fish-eye effect_. Estas distorsiones pueden ser descritas a traves de una lista de _coeficientes de distorción_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estimar los parámetros intrínsecos de la cámara se utilizarán los dos sets de calibración (en ambos sets el patrón es de 8x6). Una vez que se obtengan los resultados se los analizará para determinar cuál es el más indicado para el problema.\n",
    "Se utilizará el método _calibrateCamera_ que provee _openCV_ para hacer las estimaciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessBoardSize  = (8, 6)\n",
    "squareSize = 28\n",
    "\n",
    "# Finds the corners of the images\n",
    "def findCorners(imgs, plot=True, maxCount = 25, epsilon = 0.001, flag=cv.CALIB_CB_ADAPTIVE_THRESH):\n",
    "    objp = np.zeros((np.prod(chessBoardSize), 3),  dtype=np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:chessBoardSize[0], 0:chessBoardSize[1]].T.reshape(-1, 2)\n",
    "    objp = objp * squareSize\n",
    "    imgPoints = []\n",
    "    objPoints = []\n",
    "    criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_MAX_ITER, maxCount, epsilon)\n",
    "    cb_flags = flag \n",
    "    for imgName, img in imgs.items():\n",
    "        img = img.copy()\n",
    "        imgGray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv.findChessboardCorners(imgGray, chessBoardSize, flags=cb_flags)\n",
    "        if ret:\n",
    "            objPoints.append(objp)\n",
    "            corners_subp = cv.cornerSubPix(imgGray, corners, (5, 5), (-1, -1), criteria)\n",
    "            imgPoints.append(corners_subp)\n",
    "            cv.drawChessboardCorners(img, chessBoardSize, corners_subp, ret)\n",
    "            if plot:\n",
    "                plotter(img, imgName)\n",
    "    return imgPoints, objPoints\n",
    "\n",
    "# Calibrates the camera based on the parameters\n",
    "def calibrateCamera(objPoints, imgPoints, width, height, returnValues=True):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objPoints, imgPoints, (width, height), None, None)\n",
    "    print('Camera Matrix: \\n{}'.format(mtx))\n",
    "    print('\\nDistortion Coefficients: \\n{}\\n'.format(dist))\n",
    "    if returnValues:\n",
    "        return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las funciones creadas se procede a calibrar la cámara para los distintos sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPointsSet1, objPointsSet1 = findCorners(calibrationSet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightSet1, widthSet1, _ = calibrationSet1[CALIBRATION_IMG_NAME].shape\n",
    "cameraMatrixSet1, distortionCoefficientsSet1 = calibrateCamera(objPointsSet1, imgPointsSet1, widthSet1, heightSet1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPointsSet2, objPointsSet2 = findCorners(calibrationSet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightSet2, widthSet2, _ = calibrationSet1[CALIBRATION_IMG_NAME].shape\n",
    "cameraMatrixSet2, distortionCoefficientsSet2 = calibrateCamera(objPointsSet2, imgPointsSet2, widthSet2, heightSet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar estos resultados se puede notar que las distancias focales en el Set 1 son similares y su diferencia no es tan grande como la del Set 2. Con respecto al centro óptico, en ambos casos se encuentran a una distancia significativa del centro real de la imagen (en el caso ideal deberia encontrarse en _Width_ / 2 y _Height_ / 2, o sea 320 y 240), pero de los dos, el que se encuentra más cerca de estos valores es el centro óptico del set 1.\n",
    "Algo a notar que no se encuentra en estas estimaciones es que el Set 1 posee 20 imágenes, mientras que el Set 2 posee 10. Se sabe que mientras más imágenes se tengan mejor será la estimación.\n",
    "Se concluye en base a estas tres observaciones que el mejor set de calibración es el **Set 1**, y por lo tanto es el que se utilizará en las siguientes secciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Calibración Extrínseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros extrínsecos son los parámetros que relacionan a la cámara con el mundo.  A diferencia de los parámetros intrínsecos, estos son distintos dependiendo de la toma que se tenga.\n",
    "El proceso a realizar es similar al anterior, solo que ahora se buscan las coordenadas del mundo real de los puntos **3D** utilizando la imagen que se encuentra junto con los bloques.\n",
    "Primero se obtienen las esquinas de la imagen 'imgCalExtr' utilizando la misma función que en la sección anterior. Una vez que se obtienen las esquinas se utiliza la función `solvePnP`. Esta función lo que hace es estimar la posición de un objeto dados un conjunto de puntos del objeto, su correspondiente proyección, la matriz intrínseca de la cámara y los coeficientes de distorción . Esta función devuelve los vectores de rotación y traslación que transforman un punto 3D en un punto que se encuentre en las coordenadas de la cámara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chessboard has the same size as before\n",
    "extrinsicImgPoints, extrinsicObjPoints = findCorners({EXTRA_IMG: extrinsicCalibration})\n",
    "retval, rvecs, translationVec = cv.solvePnP(\n",
    "    extrinsicObjPoints[0],\n",
    "    extrinsicImgPoints[0],\n",
    "    cameraMatrixSet1,\n",
    "    distortionCoefficientsSet1,\n",
    "    useExtrinsicGuess=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotationMatrix = cv.Rodrigues(rvecs)[0]\n",
    "print(f'''Rotation Matrix: \n",
    "{rotationMatrix}\\n''')\n",
    "print(f'''Translation:\n",
    "{translationVec}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Búsqueda de bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las imagenes de los bloques se encuentran binarizadas y corregidas por el preprocesamiento que se realizo anteriormente, se puede utilizar la función _findContours_ que provee openCV para obtener los contornos de los bloques. Esta función trabaja sobre imágenes binarias y devuelve un conjunto de puntos que se cree que son parte del contorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockContours = {}\n",
    "\n",
    "for blockName, blockImg in finalBlocks.items():\n",
    "    contours, hier = cv.findContours(blockImg, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    blockContours[blockName] = contours\n",
    "    output = originalBlocks[blockName].copy()\n",
    "    cv.drawContours(output, contours, -1, (255,0,0),2)\n",
    "    plotter(output, blockName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que los bordes de los bloques son captados de forma correcta, algunos con ciertas irregularidades pero en la mayoría de los casos se los capta bien. A continuación se escriben funciones auxiliares para obtener los datos de los contornos de los bloques (área, lados, centroides, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAspectRatio(contour):\n",
    "    x,y,width,height = cv.boundingRect(contour)\n",
    "    return np.round(float(width) / height, 2)\n",
    "\n",
    "# Returns the centroids (cx, cy)\n",
    "def getCentroid(moment, area):\n",
    "    return (int(moment['m10'] / area), int(moment['m01'] / area))\n",
    "\n",
    "# Returns the angle in degrees\n",
    "def getOrientation(contour):\n",
    "    (x, y), (MA, mA), angle = cv.fitEllipse(contour)\n",
    "    return (int(x), int(y)), (int(MA), int(mA)), np.round(angle)\n",
    "\n",
    "# Returns (width, height) of the rectangle\n",
    "def getSides(contour):\n",
    "    return cv.minAreaRect(contour)[1]\n",
    "\n",
    "# Returns the corners of the rectangle\n",
    "def getCorners(contour):\n",
    "    rectangule = cv.minAreaRect(contour)\n",
    "    box = cv.boxPoints(rectangule)\n",
    "    return np.int0(box) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info here: https://en.wikipedia.org/wiki/Image_moment\n",
    "# Constants to get the info easily\n",
    "AREA = 'area'\n",
    "PERIMETER = 'perimeter'\n",
    "CENTER = 'center'\n",
    "SIDES = 'sides'\n",
    "CORNERS = 'corners'\n",
    "ASPECT_RELATION = 'aspectRelation'\n",
    "ORIENTATION = 'orientation'\n",
    "CONTOUR = 'contour'\n",
    "MIN_AREA = 8000 # According to the TP, the area is 8450\n",
    "\n",
    "def getContoursInfo(blockContours):\n",
    "    contoursInfo = {}\n",
    "    \n",
    "    for blockName, contours in blockContours.items():\n",
    "        for ctr in contours:\n",
    "            information = {}\n",
    "            moment = cv.moments(ctr)\n",
    "            area = int(moment['m00'])\n",
    "            if area <= MIN_AREA: # Is not a contour of a block\n",
    "                continue\n",
    "            information[AREA] = area\n",
    "            information[PERIMETER] = int(cv.arcLength(ctr,True))\n",
    "            information[CENTER] = getCentroid(moment, area)\n",
    "            information[SIDES] = getSides(ctr)\n",
    "            information[ASPECT_RELATION] = getAspectRatio(ctr)\n",
    "            information[ORIENTATION] = getOrientation(ctr)\n",
    "            information[CORNERS] = getCorners(ctr)\n",
    "            information[CONTOUR] = ctr\n",
    "            if isSpecialImage(blockName):\n",
    "                # This image is special because there are two blocks\n",
    "                contoursInfo[blockName] = contoursInfo.get(blockName, []) + [information]\n",
    "                continue\n",
    "            contoursInfo[blockName] = information\n",
    "            \n",
    "    return contoursInfo\n",
    "\n",
    "contoursInfo = getContoursInfo(blockContours) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada una de las imágenes analizadas se marcará en rojo los bordes del bloque y con un punto negro dónde se detectó el centro del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for blockName, info in contoursInfo.items():\n",
    "    if isSpecialImage(blockName):\n",
    "            finalImg = originalBlocks[blockName].copy()\n",
    "            for block_i_info in info:\n",
    "                finalImg = drawContours(finalImg, block_i_info)\n",
    "            plotter(finalImg, blockName)\n",
    "            continue\n",
    "    plotter(drawContours(originalBlocks[blockName], info), blockName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los datos obtenidos se encuentran en unidades de píxeles, por lo que para pasarlos a valores del mundo real se tienen que realizar las siguientes operaciones. En primer lugar se sabe que la ecuación para convertir coordenadas del mundo real a coordenadas en la imagen es:\n",
    "\n",
    "\\begin{equation}\n",
    "    s * \n",
    "    \\begin{bmatrix}\n",
    "        u_s \\\\ v_s \\\\ 1\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        K\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        R_k | t_k\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix} \n",
    "        X_w \\\\ Y_w \\\\ Z_w \\\\ 1 \n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Dado que K es una matriz de 3x3 y [$R_k$ | $t_k$] es de 3x4, se puede escribir a la ecuación de otra forma para trabajar con matrices cuadradas, quedando de la siguiente manera:\n",
    "\n",
    "\\begin{equation}\n",
    "    s * \n",
    "    \\begin{bmatrix}\n",
    "        u_s \\\\ v_s \\\\ 1 \\\\ d\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        K && 0 \\\\\n",
    "        0^T && 1\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        R && t \\\\\n",
    "        0^T && 1\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix} \n",
    "        X_w \\\\ Y_w \\\\ Z_w \\\\ 1 \n",
    "    \\end{bmatrix} =\n",
    "    P\n",
    "    \\begin{bmatrix} \n",
    "        X_w \\\\ Y_w \\\\ Z_w \\\\ 1 \n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Al trabajar con este sistema tenemos la libertad de mapear la mapear la última fila donde deseemos. En este caso se tomará $d=0$ dado que lo que se busca obtener son las coordenadas del mundo. \n",
    "Como **P** es una matriz cuadrada realizar el despeje consiste en encontrar su inversa y multiplicarla por las coordenadas de la imagen. O sea, la ecuación resultante, y que se utilizará, es:\n",
    "\n",
    "\\begin{equation}\n",
    "    s *\n",
    "    P^{-1}\n",
    "    \\begin{bmatrix}\n",
    "        u_s \\\\ v_s \\\\ 1 \\\\ 0\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix} \n",
    "        X_w \\\\ Y_w \\\\ Z_w \\\\ 1 \n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Se agregará una función que realice todo estos pasos y devuelva como resultado las coordenadas deseadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to square matrices\n",
    "newRow = np.array([0., 0., 0., 1.])\n",
    "intrinsicMatrix = np.append(cameraMatrixSet1, np.zeros((3, 1)), axis=1)\n",
    "intrinsicMatrix = np.append(intrinsicMatrix, [newRow], axis=0)\n",
    "print(f'''Intrinsic Matrix:\n",
    "{intrinsicMatrix}\\n''')\n",
    "\n",
    "extrinsicMatrix = np.append(rotationMatrix, translationVec, axis=1)\n",
    "extrinsicMatrix = np.append(extrinsicMatrix, [newRow], axis=0)\n",
    "print(f'''Extrinsic Matrix:\n",
    "{extrinsicMatrix}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proyectionMatrix = np.dot(intrinsicMatrix, extrinsicMatrix)\n",
    "print(f'''Proyection Matrix:\n",
    "{proyectionMatrix}\\n''')\n",
    "\n",
    "invertedProyectionMatrix = np.linalg.inv(proyectionMatrix)\n",
    "print(f'''Inverted Proyection Matrix:\n",
    "{invertedProyectionMatrix}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the 3D coordinates of a point in an image\n",
    "def get3DCoordinates(imageCoordinates):\n",
    "    uv = np.append(imageCoordinates, [np.array([1, 0])]).T\n",
    "    return (translationVec[2] * np.dot(invertedProyectionMatrix, uv))[:3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get3DCoordinates(np.array([353, 326]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the width and height in millimeters\n",
    "def getSidesInMillimeters(v):\n",
    "    v = [get3DCoordinates(x)[:2] for x in v]\n",
    "    w = np.sqrt((v[1][0]-v[0][0])**2+(v[1][1]-v[0][1])**2)\n",
    "    h = np.sqrt((v[3][0]-v[0][0])**2+(v[3][1]-v[0][1])**2)\n",
    "    if w > h:\n",
    "        w = np.sqrt((v[1][0]-v[3][0])**2+(v[1][1]-v[3][1])**2)\n",
    "    else:\n",
    "        h = np.sqrt((v[1][0]-v[3][0])**2+(v[1][1]-v[3][1])**2)\n",
    "    if w > h:\n",
    "        return (w, h)\n",
    "    else:\n",
    "        return (h, w)\n",
    "\n",
    "# Returns the centroid in millimeters\n",
    "def getCentroidInMillimeters(centroid):\n",
    "    return get3DCoordinates(centroid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contoursInfo['imgBloque1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the centroid of each block in millimeters. Format: (Cx, Cy)\n",
    "def printCentroidsInMillimeters(blocksInfo):\n",
    "    printInfo = lambda imgName, cx, cy: print(f'''Image: {imgName}\n",
    "        Centroid: ({np.round(cx, 4)},{np.round(cy, 4)})\n",
    "        '''\n",
    "    ) \n",
    "    for imgName in blocksInfo.keys():\n",
    "        if isSpecialImage(imgName):\n",
    "            for infoSpecialBlock in blocksInfo[imgName]:\n",
    "                cx, cy, _ = getCentroidInMillimeters(infoSpecialBlock[CENTER])\n",
    "                printInfo(imgName, cx, cy)\n",
    "            continue\n",
    "        cx, cy, _ = getCentroidInMillimeters(blocksInfo[imgName][CENTER])\n",
    "        printInfo(imgName, cx, cy)\n",
    "        \n",
    "printCentroidsInMillimeters(contoursInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Validación del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Medición de bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir los bloques en milímetros se reutilizarán funciones creadas anteriormente como además la información de los bloques que se fue obteniendo a lo largo de cada sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prints the area, width and height of each block in millimeters\n",
    "def printSidesInMillimeters(blocksInfo):\n",
    "    printInfo = lambda imgName, blockWidth, blockHeight: print(f'''Image: {imgName}\n",
    "        Area: {np.round(blockWidth * blockHeight, 4)}\n",
    "        Width: {np.round(blockWidth, 4)}\n",
    "        Height: {np.round(blockHeight, 4)}\n",
    "        '''\n",
    "    ) \n",
    "    for imgName in blocksInfo.keys():\n",
    "        if isSpecialImage(imgName):\n",
    "            for infoSpecialBlock in blocksInfo[imgName]:\n",
    "                blockWidth, blockHegith = getSidesInMillimeters(infoSpecialBlock[CORNERS])\n",
    "                printInfo(imgName, blockWidth, blockHegith)\n",
    "            continue\n",
    "        blockWidth, blockHegith, = getSidesInMillimeters(blocksInfo[imgName][CORNERS])\n",
    "        printInfo(imgName, blockWidth, blockHegith)\n",
    "\n",
    "printSidesInMillimeters(contoursInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizará lo mismo que en las secciones anteriores, solo que esta vez aplicando todo a los bloques del desafío. Primero se cargan las imágenes en una nueva variable y luego se realiza un preprocesamiento para eliminar todo el ruído que puede afectar al análisis de los bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challengeBlocks = loadImages(BLOCKS_CHALLENGE_PATH)\n",
    "extrinsicCalibrationChallenge = challengeBlocks[EXTRA_IMG]\n",
    "del challengeBlocks[EXTRA_IMG]\n",
    "debug(challengeBlocks, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, estas imágenes poseen mucho más ruido que las anteriores, por ejemplo se puede ver un cable azul que atraviesa la escena, o una botella de gaseosa y partes de otros bloques que se encuentran afuera del tablero verde. A continuación se utiliza las máscaras creadas anteriormente para ver si con esto se solucionan estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply board mask\n",
    "challengeBlocksWithMask = {}\n",
    "for imgName, img in challengeBlocks.items():\n",
    "    img = cv.medianBlur(img - 50, 5) # In order to reduce the bright of each image\n",
    "    challengeBlocksWithMask[imgName] = cv.bitwise_and(img, img, mask=blocksMask)\n",
    "\n",
    "# DEBUG\n",
    "debug(challengeBlocksWithMask, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply block mask and change imgs to gray scale\n",
    "for imgName, img in challengeBlocksWithMask.items():\n",
    "    mask_i = cv.inRange(img, meanBlocks - stdBlocks * 17,  meanBlocks + stdBlocks * 6)\n",
    "    challengeBlocksWithMask[imgName] = cv.cvtColor(cv.bitwise_and(img, img, mask=mask_i), cv.COLOR_RGB2GRAY)\n",
    "\n",
    "debug(challengeBlocksWithMask, grayScale=True, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, bajando el brillo de las imágenes y aplicando las mismas máscaras que antes se pueden obtener bien las formas de los bloques. Dado que sigue habiendo ruido en las imágenes se las binarizá para luego aplicarles operaciones morfológicas para eliminar la mayor cantidad de ruido que sea posible. Al igual que en el preprocesamiento anterior, se graficarán los histogramas de las 3 imágenes para poder establecer el _threshold_ a utilizar en el método de binarización de Otsu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(challengeBlocksWithMask, amountOfBlocks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente este resultado es el esperado, dado que el porcentaje de negro en cada una de las imágenes es mucho mayor que el porcentaje gris que representa a los bloques. Se utiliza el mismo threshold que en el caso anterior para binarizar a las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binarizedChallengeBlocks = otsuBinarization(challengeBlocksWithMask)\n",
    "debug(binarizedChallengeBlocks, grayScale=True, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplicará la operación morfológica de erosión con un _Structural Element_ de 3x3 un total de 3 veces y luego la operación de dilatación con un structural element del mismo tamaño, pero un total de 4 veces. Por último, al resultado de esas operaciones se les aplica un filtro de mediana con un kernel de 5x5. El resultado de todas estas operaciones se guarda en la variable **finalChallengeBlocks** que se utilizará más adelante para buscar los contornos y propiedades de los bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernelErotion = np.ones((3,3), np.uint8)\n",
    "kernelDilation = np.ones((3,3), np.uint8)\n",
    "finalChallengeBlocks = {}\n",
    "for imgName, binarizedBlock in binarizedChallengeBlocks.items():\n",
    "    img = binarizedBlock.copy()\n",
    "    img = cv.erode(img, kernelErotion, iterations=3)\n",
    "    img = cv.dilate(img, kernelDilation, iterations=4)\n",
    "    img = cv.medianBlur(img, 5)\n",
    "    finalChallengeBlocks[imgName] = img\n",
    "    plotter(img, imgName, grayScale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challengeBlockContours = {}\n",
    "\n",
    "for blockName, blockImg in finalChallengeBlocks.items():\n",
    "    contours, hier = cv.findContours(blockImg, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    challengeBlockContours[blockName] = contours\n",
    "    output = challengeBlocks[blockName].copy()\n",
    "    cv.drawContours(output, contours, -1, (255,0,0),2)\n",
    "    plotter(output, blockName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contoursInfo = getContoursInfo(challengeBlockContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blockName, info in contoursInfo.items():\n",
    "    if isSpecialImage(blockName):\n",
    "            finalImg = challengeBlocks[blockName].copy()\n",
    "            for block_i_info in info:\n",
    "                finalImg = drawContours(finalImg, block_i_info)\n",
    "            plotter(finalImg, blockName)\n",
    "            continue\n",
    "    plotter(drawContours(challengeBlocks[blockName], info), blockName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printBlocksInfo(contoursInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que los contornos fueron hallados de forma exitosa así como las distintas propiedades de los bloques. Los resultados en milímetros para los bloques del desafío se muestran en los siguientes bloques de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printCentroidsInMillimeters(contoursInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printSidesInMillimeters(contoursInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _, _ = np.dot(proyectionMatrix, np.array([0,0,0,1]).T) * 1/translationVec[2]\n",
    "np.round(x, 4), np.round(y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter(extrinsicCalibration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
