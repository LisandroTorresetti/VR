{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo práctico Integrador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alumno:** Torresetti Lisandro\n",
    "\n",
    "**Padrón:** 99846\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Realizar un programa que permita determiar la pose de las piezas dispuestas en la zona de trabajo de manera que el robot pueda tomarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import PIL.ExifTags\n",
    "import PIL.Image\n",
    "import pprint\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths\n",
    "\n",
    "BLOCKS_PATH = './imagenes/img_bloques'\n",
    "BLOCKS_CHALLENGE_PATH = './imagenes/img_bloques_desafio'\n",
    "CALIBRATION_SET_1 = './imagenes/img_cal_set1'\n",
    "CALIBRATION_SET_2 = './imagenes/img_cal_set2'\n",
    "\n",
    "# Constants\n",
    "\n",
    "EXTRA_IMG = 'imgCalExtr'\n",
    "IMG_NAME = 'imgBloque'\n",
    "CALIBRATION_IMG_NAME = 'img_cal1'\n",
    "\n",
    "# Debug\n",
    "IMGS_DEBUG = ['imgBloque1', 'imgBloque2', 'imgBloque3', 'imgBloque4', 'imgBloque16']\n",
    "CHALLENGE_IMGS = IMGS_DEBUG[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to make the plots\n",
    "def plotter(image, title = '', imgSize = (16,9), grayScale = False):\n",
    "    plt.figure(figsize=imgSize)\n",
    "    plt.title(title, fontsize = 16, fontweight = \"bold\")\n",
    "    plt.imshow(image) if not grayScale else plt.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "# Auxiliary function to load all the images from path\n",
    "def loadImages(path):\n",
    "    imgNames = glob(path + '/*')\n",
    "    result = {}\n",
    "    for imgName in imgNames:\n",
    "        img = cv.imread(imgName)\n",
    "        result[re.sub(r'^.*/([^.]*).*$', r'\\1', imgName)] = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    return result\n",
    "\n",
    "# Creates a mask from the image and the specified position. Remember: in OpenCv the coorinates are (Y, X)\n",
    "def createMask(img, position, lowerMultiplier = 6, upperMultiplier = 6):\n",
    "    initialPoint, endPoint = position\n",
    "    colorMean, colorStd = cv.meanStdDev(img[initialPoint[1]:endPoint[1], initialPoint[0]:endPoint[0], :])\n",
    "    return cv.inRange(img, colorMean - colorStd * lowerMultiplier,  colorMean + colorStd * upperMultiplier)\n",
    "\n",
    "# Applies a mask to the img. Returns a new image with the mask applied\n",
    "def applyMask(img, mask):\n",
    "    return cv.bit\n",
    "\n",
    "# Plot the histogram for the first 'amountOfBlocks' blocks\n",
    "def plotHistograms(imgs, bins = 50, amountOfBlocks = 5):\n",
    "    fig, axs = plt.subplots(amountOfBlocks)\n",
    "    fig.suptitle('Histograms', fontsize=18, fontweight='bold')\n",
    "    imgsNames = [IMG_NAME + str(i) for i in range(1, amountOfBlocks + 1)]\n",
    "    xTicks = np.arange(0, 260, 10)\n",
    "    yTicks = np.arange(0, 300000, 30000)\n",
    "    for imgNum, imgName in enumerate(imgsNames):\n",
    "        axs[imgNum].set_title(imgName, fontsize = 16, fontweight='bold')\n",
    "        axs[imgNum].grid()\n",
    "        axs[imgNum].hist(imgs[imgName].ravel(),bins,[0,256], color='orange')\n",
    "        axs[imgNum].set_xticks(xTicks)\n",
    "        axs[imgNum].set_yticks(yTicks)\n",
    "    \n",
    "    fig.set_size_inches(16, 10)\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "# Performs the Otsu binarization mehtod. Returns a dictionary with the images binarized\n",
    "def otsuBinarization(imgs, thresh = 100):\n",
    "    result = {}\n",
    "    for imgName, img in imgs.items():\n",
    "        ret, imgBin = cv.threshold(img, thresh, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "        result[imgName] = imgBin\n",
    "    return result\n",
    "\n",
    "# Prints the contour info for an image\n",
    "def printBlocksInfo(contoursInfo):\n",
    "    print('RESULTS')\n",
    "    for blockName, info in contoursInfo.items():\n",
    "        if isSpecialImage(blockName):\n",
    "            for block_i_info in info:\n",
    "                printInfo(blockName, block_i_info)\n",
    "            continue\n",
    "            \n",
    "        printInfo(blockName, info)\n",
    "\n",
    "# Prints the info of a block with a format\n",
    "def printInfo(blockName, info):\n",
    "    print(f'''\n",
    "                Block Num: {blockName}\n",
    "\n",
    "                    Area: {info[AREA]}\n",
    "                    Perimeter: {info[PERIMETER]}\n",
    "                    Width: {np.round(info[SIDES][0], 4)}\n",
    "                    Height: {np.round(info[SIDES][1], 4)}\n",
    "                    Centroid: {info[CENTER]}\n",
    "                    Aspect Relation: {info[ASPECT_RELATION]}\n",
    "                    Orientation: {info[ORIENTATION][2]}\n",
    "                '''\n",
    "    )\n",
    "\n",
    "# Returns if the image is the one who contains more than one block\n",
    "def isSpecialImage(imgName):\n",
    "    return imgName == IMG_NAME + '16'\n",
    "\n",
    "# Draws the bounding box and the center of the block. Returns an image with the draws\n",
    "def drawContours(img, blockInfo):\n",
    "    outputImg = img.copy()\n",
    "    contour = blockInfo[CONTOUR]\n",
    "    cv.circle(outputImg, blockInfo[CENTER], radius=5, color=(0, 0, 0), thickness=-3)\n",
    "    approx = cv.approxPolyDP(contour, 0.1 * cv.arcLength(contour, True), True)\n",
    "    cv.drawContours(outputImg, [approx], 0, (255, 0, 0), 2)\n",
    "    return outputImg\n",
    "\n",
    "# For debugging\n",
    "def debug(imgs, grayScale=False, debugImgs=IMGS_DEBUG):\n",
    "    for imgName in debugImgs:\n",
    "        plotter(imgs[imgName], imgName, grayScale=grayScale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Se cargan las imágenes de los bloques y las de los sets de calibración. Una vez que se carguen todas se procede a preprocesarlas para corregirlas y eliminar el ruido que posean y que pueda interferir en el análisis de las futuras secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originalBlocks = loadImages(BLOCKS_PATH)\n",
    "calibrationSet1 = loadImages(CALIBRATION_SET_1)\n",
    "calibrationSet2 = loadImages(CALIBRATION_SET_2)\n",
    "\n",
    "# There is an image for the extrinsic calibration, I will store it in some variable and \n",
    "# then it will be delete of the set of block images\n",
    "extrinsicCalibration = originalBlocks[EXTRA_IMG]\n",
    "del originalBlocks[EXTRA_IMG]\n",
    "\n",
    "# Just for check if its all right\n",
    "debug(originalBlocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea una máscara con el tablero verde para poder eliminar el ruido de los otros elementos que se encuentran en la imagen. Para crearla, se toma una porción de 'imgBloque1' y otra de 'imgBloque2' para luego hacer un OR entre ambas y obtener una máscara que sólo abarque el tablero verde. De esta forma todos los elementos que no se encuentren en el tablero serán 'eliminados'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position = ((x1, y1), (x2, y2))\n",
    "maskPosition1 = ((125, 280), (480, 450))\n",
    "blocksMask1 = createMask(originalBlocks['imgBloque1'], maskPosition1)\n",
    "\n",
    "maskPosition2 = ((125, 50), (480, 250))\n",
    "blocksMask2 = createMask(originalBlocks['imgBloque4'], maskPosition2)\n",
    "blocksMask = cv.bitwise_or(blocksMask1, blocksMask2)\n",
    "blocksMask = cv.medianBlur(blocksMask, 5)\n",
    "\n",
    "blocksWithMask = {}\n",
    "for imgName, img in originalBlocks.items():\n",
    "    img = cv.medianBlur(img, 5)\n",
    "    blocksWithMask[imgName] = cv.bitwise_and(img, img, mask=blocksMask)\n",
    "\n",
    "# DEBUG\n",
    "debug(blocksWithMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener una imagen que solo posea la figura del bloque se vuelve a crear una máscara, pero esta vez con porciones de los bloques, para hacer un promedio entre la media y el desvío estandar de cada uno de ellos, con el fin de que sea más general la máscara y no se base en los datos de un solo bloque. Se utilizarán los bloques de las imágenes 1, 2 y 3 para obtener la máscara deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocks Positions\n",
    "block1 = ((325, 110), (400, 125))\n",
    "block2 = ((285, 150), (325, 195))\n",
    "block3 = ((400, 150), (450, 200))\n",
    "blocks = [block1, block2, block3]\n",
    "\n",
    "# Draw a red line to verify the positions\n",
    "for blockNum, block in enumerate(blocks):\n",
    "    testImg = blocksWithMask[IMG_NAME + str(blockNum + 1)].copy()\n",
    "    cv.line(testImg, block[0], block[1], (255,0,0), 5)\n",
    "    plotter(testImg, IMG_NAME + str(blockNum + 1))\n",
    "\n",
    "# Get statistics about each block to compute the mask\n",
    "totalMeanBlocks = 0\n",
    "totalStdBlocks = 0\n",
    "for blockNum, blockPosition in enumerate(blocks):\n",
    "    initialPoint, endPoint = blockPosition\n",
    "    imgName = IMG_NAME + str(blockNum + 1)\n",
    "    blockImg = blocksWithMask[imgName][initialPoint[1]:endPoint[1], initialPoint[0]:endPoint[0], :]\n",
    "    meanBlock, stdBlock = cv.meanStdDev(blockImg)\n",
    "    totalMeanBlocks += meanBlock\n",
    "    totalStdBlocks += stdBlock\n",
    "    plotter(blockImg, imgName, imgSize=(8,5))\n",
    "\n",
    "meanBlocks = totalMeanBlocks / len(blocks)\n",
    "stdBlocks = totalStdBlocks / len(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {meanBlocks} \\nStd: {stdBlocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coninuación se aplican los datos obtenidos a todas las imágenes para obtnener sólo la figura de los bloques en cada una de ellas. Los resultados serán guardados en **blocksWithMask** en escala de grises, 'pisando' los valores que se obtuvieron anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgName, img in blocksWithMask.items():\n",
    "    mask_i = cv.inRange(img, meanBlocks - stdBlocks * 6,  meanBlocks + stdBlocks * 6)\n",
    "    blocksWithMask[imgName] = cv.cvtColor(cv.bitwise_and(img, img, mask=mask_i), cv.COLOR_RGB2GRAY)\n",
    "\n",
    "debug(blocksWithMask, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las imágenes poseen ciertas imperfecciones, como por ejemplo puntos negros dentro de los bloques o problemas en los bordes de los mismos. Se procede a binarizarlas para poder aplicarles operaciónes morfológicas y así corregir estas imperfecciones. Antes de realizar esto, se grafican los histogramas de dos imágenes para ver la distribución de los valores y así poder elegir un valor de _threshold_ adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(blocksWithMask, amountOfBlocks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de los histogramas es el esperado, ya que el porcentaje de color del bloque es pequeño en comparación con toda la imagen que es casi en su totalidad negra. Se utilizará un _threshold_ de 100 para realizar la binarización de las imágenes por el método de **Otsu** que se describe a continuación.\n",
    "\n",
    "**// ToDo: poner descripcion de otsu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binarizedBlocks = otsuBinarization(blocksWithMask)\n",
    "debug(binarizedBlocks, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar los problemas mencionados y que se encuentran a simple vista, se aplicará la operación morfológica de dilatación con un _Structural element_ de 4x1. Al resultado de esta operación se le aplicará un filtro de mediana con un kernel de 5x5. El resultado de estas operaciones se almacenará en la variable _final blocks_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will contain the final result of all the previous operation \n",
    "# plus the next one for each block image\n",
    "kernelDilate =np.ones((4,1), np.uint8)\n",
    "finalBlocks = {}\n",
    "for blockName, blockImg in binarizedBlocks.items():\n",
    "    finalBlocks[blockName] = cv.medianBlur(cv.dilate(blockImg, kernelDilate), 5)\n",
    "\n",
    "debug(finalBlocks, grayScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto se da por finalizado el preprocesamiento de las imágenes. Los resultados obtenidos se utilizarán en las siguientes secciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Calibración Intrínseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de parámetros intrínsecos describe todos los parámetros internos de la cámara. La matriz contiene las distancias focales ($f_x$ y $f_y$) y los centros ópticos ($c_x$ y $c_y$) expresados en coordenadas de píxeles. En un modelo ideal $f_x = f_y = f$, sin embargo esto en la realidad estos valores pueden diferir debido a fallas en el sensor de la cámara digital. La matriz de parámetros intrínsecos es la siguiente:\n",
    "$$\\begin{bmatrix} fx & s & cx \\\\ 0 & fy & cy \\\\ 0 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "Una cámara puede estar sujeta a distorsiones radiales o tangenciales, llevando a un _fish-eye effect_. Estas distorsiones pueden ser descritas a traves de una lista de _coeficientes de distorción_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estimar los parámetros intrínsecos de la cámara se utilizarán los dos sets de calibración (en ambos sets el patrón es de 8x6). Una vez que se obtengan los resultados se los analizará para determinar cuál es el más indicado para el problema.\n",
    "Se utilizará el método _calibrateCamera_ que provee _openCV_ para hacer las estimaciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessBoardSize  = (8, 6)\n",
    "objp = np.zeros((np.prod(chessBoardSize), 3),  dtype=np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessBoardSize[0], 0:chessBoardSize[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Finds the corners of the images\n",
    "def findCorners(imgs, plot=True, maxCount = 25, epsilon = 0.001, flag=cv.CALIB_CB_ADAPTIVE_THRESH):\n",
    "    imgPoints = []\n",
    "    objPoints = []\n",
    "    criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_MAX_ITER, maxCount, epsilon)\n",
    "    cb_flags = flag \n",
    "    for imgName, img in imgs.items():\n",
    "        img = img.copy()\n",
    "        imgGray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv.findChessboardCorners(imgGray, chessBoardSize, flags=cb_flags)\n",
    "        if ret:\n",
    "            objPoints.append(objp)\n",
    "            corners_subp = cv.cornerSubPix(imgGray, corners, (5, 5), (-1, -1), criteria)\n",
    "            imgPoints.append(corners_subp)\n",
    "            cv.drawChessboardCorners(img, chessBoardSize, corners_subp, ret)\n",
    "            if plot:\n",
    "                plotter(img, imgName)\n",
    "    return imgPoints, objPoints\n",
    "\n",
    "# Calibrates the camera based on the parameters\n",
    "def calibrateCamera(objPoints, imgPoints, width, height, returnMatrix=False):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objPoints, imgPoints, (width, height), None, None)\n",
    "    print('Camera Matrix: \\n{}'.format(mtx))\n",
    "    print('\\nDistortion Coefficients: \\n{}\\n'.format(dist))\n",
    "    if returnMatrix:\n",
    "        return mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las funciones creadas se procede a calibrar la cámara para los distintos sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPointsSet1, objPointsSet1 = findCorners(calibrationSet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightSet1, widthSet1, _ = calibrationSet1[CALIBRATION_IMG_NAME].shape\n",
    "cameraMatrixSet1 = calibrateCamera(objPointsSet1, imgPointsSet1, widthSet1, heightSet1, returnMatrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPointsSet2, objPointsSet2 = findCorners(calibrationSet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightSet2, widthSet2, _ = calibrationSet1[CALIBRATION_IMG_NAME].shape\n",
    "cameraMatrixSet2 = calibrateCamera(objPointsSet2, imgPointsSet2, widthSet2, heightSet2, returnMatrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Calibración Extrínseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Búsqueda de bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las imagenes de los bloques se encuentran binarizadas y corregidas por el preprocesamiento que se realizo anteriormente, se puede utilizar la función _findContours_ que provee openCV para obtener los contornos de los bloques. Esta función trabaja sobre imágenes binarias y devuelve un conjunto de puntos que se cree que son parte del contorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockContours = {}\n",
    "\n",
    "for blockName, blockImg in finalBlocks.items():\n",
    "    contours, hier = cv.findContours(blockImg, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    blockContours[blockName] = contours\n",
    "    output = originalBlocks[blockName].copy()\n",
    "    cv.drawContours(output, contours, -1, (255,0,0),2)\n",
    "    plotter(output, blockName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que los bordes de los bloques son captados de forma correcta, algunos con ciertas irregularidades pero en la mayoría de los casos se los capta bien. A continuación se escriben funciones auxiliares para obtener los datos de los contornos de los bloques (área, lados, centroides, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAspectRatio(contour):\n",
    "    x,y,width,height = cv.boundingRect(contour)\n",
    "    return np.round(float(width) / height, 2)\n",
    "\n",
    "# Returns the centroids (cx, cy)\n",
    "def getCentroid(moment, area):\n",
    "    return (int(moment['m10'] / area), int(moment['m01'] / area))\n",
    "\n",
    "# Returns the angle in degrees\n",
    "def getOrientation(contour):\n",
    "    (x, y), (MA, mA), angle = cv.fitEllipse(contour)\n",
    "    return (int(x), int(y)), (int(MA), int(mA)), np.round(angle)\n",
    "\n",
    "# Returnrs (width, height) of the rectangle\n",
    "def getSides(contour):\n",
    "    return cv.minAreaRect(contour)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info here: https://en.wikipedia.org/wiki/Image_moment\n",
    "# Constants to get the info easily\n",
    "AREA = 'area'\n",
    "PERIMETER = 'perimeter'\n",
    "CENTER = 'center'\n",
    "SIDES = 'sides'\n",
    "ASPECT_RELATION = 'aspectRelation'\n",
    "ORIENTATION = 'orientation'\n",
    "CONTOUR = 'contour'\n",
    "MIN_AREA = 8000 # According to the TP, the area is 8450\n",
    "\n",
    "def getContoursInfo(blockContours):\n",
    "    contoursInfo = {}\n",
    "    \n",
    "    for blockName, contours in blockContours.items():\n",
    "        for ctr in contours:\n",
    "            information = {}\n",
    "            moment = cv.moments(ctr)\n",
    "            area = int(moment['m00'])\n",
    "            if area <= MIN_AREA: # Is not a contour of a block\n",
    "                continue\n",
    "            information[AREA] = area\n",
    "            information[PERIMETER] = int(cv.arcLength(ctr,True))\n",
    "            information[CENTER] = getCentroid(moment, area)\n",
    "            information[SIDES] = getSides(ctr)\n",
    "            information[ASPECT_RELATION] = getAspectRatio(ctr)\n",
    "            information[ORIENTATION] = getOrientation(ctr)\n",
    "            information[CONTOUR] = ctr\n",
    "            if isSpecialImage(blockName):\n",
    "                # This image is special because there are two blocks\n",
    "                contoursInfo[blockName] = contoursInfo.get(blockName, []) + [information]\n",
    "                continue\n",
    "            contoursInfo[blockName] = information\n",
    "            \n",
    "    return contoursInfo\n",
    "\n",
    "contoursInfo = getContoursInfo(blockContours) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación para cada una de las imágenes analizadas se marcará en rojo los bordes del bloque y con un punto negro dónde se detectó el centro del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blockName, info in contoursInfo.items():\n",
    "    if isSpecialImage(blockName):\n",
    "            finalImg = originalBlocks[blockName].copy()\n",
    "            for block_i_info in info:\n",
    "                finalImg = drawContours(finalImg, block_i_info)\n",
    "            plotter(finalImg, blockName)\n",
    "            continue\n",
    "    plotter(drawContours(originalBlocks[blockName], info), blockName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Validación del algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Medición de bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizará lo mismo que en las secciones anteriores, solo que esta vez aplicando todo a los bloques del desafío. Primero se cargan las imágenes en una nueva variable y luego se realiza un preprocesamiento para eliminar todo el ruído que puede afectar al análisis de los bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challengeBlocks = loadImages(BLOCKS_CHALLENGE_PATH)\n",
    "extrinsicCalibrationChallenge = challengeBlocks[EXTRA_IMG]\n",
    "del challengeBlocks[EXTRA_IMG]\n",
    "debug(challengeBlocks, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, estas imágenes poseen mucho más ruido que las anteriores, por ejemplo se puede ver un cable azul que atraviesa la escena, o una botella de gaseosa y partes de otros bloques que se encuentran afuera del tablero verde. A continuación se utiliza las máscaras creadas anteriormente para ver si con esto se solucionan estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply board mask\n",
    "challengeBlocksWithMask = {}\n",
    "for imgName, img in challengeBlocks.items():\n",
    "    img = cv.medianBlur(img - 50, 5) # In order to reduce the bright of each image\n",
    "    challengeBlocksWithMask[imgName] = cv.bitwise_and(img, img, mask=blocksMask)\n",
    "\n",
    "# DEBUG\n",
    "debug(challengeBlocksWithMask, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply block mask and change imgs to gray scale\n",
    "for imgName, img in challengeBlocksWithMask.items():\n",
    "    mask_i = cv.inRange(img, meanBlocks - stdBlocks * 17,  meanBlocks + stdBlocks * 6)\n",
    "    challengeBlocksWithMask[imgName] = cv.cvtColor(cv.bitwise_and(img, img, mask=mask_i), cv.COLOR_RGB2GRAY)\n",
    "\n",
    "debug(challengeBlocksWithMask, grayScale=True, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, bajando el brillo de las imágenes y aplicando las mismas máscaras que antes se pueden obtener bien las formas de los bloques. Dado que sigue habiendo ruido en las imágenes se las binarizá para luego aplicarles operaciones morfológicas para eliminar la mayor cantidad de ruido que sea posible. Al igual que en el preprocesamiento anterior, se graficarán los histogramas de las 3 imágenes para poder establecer el _threshold_ a utilizar en el método de binarización de Otsu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistograms(challengeBlocksWithMask, amountOfBlocks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente este resultado es el esperado, dado que el porcentaje de negro en cada una de las imágenes es mucho mayor que el porcentaje gris que representa a los bloques. Se utiliza el mismo threshold que en el caso anterior para binarizar a las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binarizedChallengeBlocks = otsuBinarization(challengeBlocksWithMask)\n",
    "debug(binarizedChallengeBlocks, grayScale=True, debugImgs=CHALLENGE_IMGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplicará la operación morfológica de erosión con un _Structural Element_ de 3x3 un total de 3 veces y luego la operación de dilatación con un structural element del mismo tamaño, pero un total de 4 veces. Por último, al resultado de esas operaciones se les aplica un filtro de mediana con un kernel de 5x5. El resultado de todas estas operaciones se guarda en la variable **finalChallengeBlocks** que se utilizará más adelante para buscar los contornos y propiedades de los bloques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernelErotion = np.ones((3,3), np.uint8)\n",
    "kernelDilation = np.ones((3,3), np.uint8)\n",
    "finalChallengeBlocks = {}\n",
    "for imgName, binarizedBlock in binarizedChallengeBlocks.items():\n",
    "    img = binarizedBlock.copy()\n",
    "    img = cv.erode(img, kernelErotion, iterations=3)\n",
    "    img = cv.dilate(img, kernelDilation, iterations=4)\n",
    "    img = cv.medianBlur(img, 5)\n",
    "    finalChallengeBlocks[imgName] = img\n",
    "    plotter(img, imgName, grayScale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challengeBlockContours = {}\n",
    "\n",
    "for blockName, blockImg in finalChallengeBlocks.items():\n",
    "    contours, hier = cv.findContours(blockImg, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    challengeBlockContours[blockName] = contours\n",
    "    output = challengeBlocks[blockName].copy()\n",
    "    cv.drawContours(output, contours, -1, (255,0,0),2)\n",
    "    plotter(output, blockName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contoursInfo = getContoursInfo(challengeBlockContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for blockName, info in contoursInfo.items():\n",
    "    if isSpecialImage(blockName):\n",
    "            finalImg = challengeBlocks[blockName].copy()\n",
    "            for block_i_info in info:\n",
    "                finalImg = drawContours(finalImg, block_i_info)\n",
    "            plotter(finalImg, blockName)\n",
    "            continue\n",
    "    plotter(drawContours(challengeBlocks[blockName], info), blockName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printBlocksInfo(contoursInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que los contornos fueron hallados de forma exitosa así como las distintas propiedades de los bloques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
